{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b1b2d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'resume_job_matching_dataset.csv' found. Loading existing data.\n",
      "\n",
      "Original Data Head:\n",
      "                                     job_description  \\\n",
      "0  Data Analyst needed with experience in SQL, Ex...   \n",
      "1  Data Scientist needed with experience in Stati...   \n",
      "2  Software Engineer needed with experience in Sy...   \n",
      "3  ML Engineer needed with experience in Python, ...   \n",
      "4  Software Engineer needed with experience in RE...   \n",
      "\n",
      "                                              resume  match_score  \n",
      "0  Experienced professional skilled in SQL, Power...            4  \n",
      "1  Experienced professional skilled in Python, De...            4  \n",
      "2  Experienced professional skilled in wait, Git,...            5  \n",
      "3  Experienced professional skilled in return, De...            4  \n",
      "4  Experienced professional skilled in REST APIs,...            5  \n",
      "\n",
      "Original Data Shape: (10000, 3)\n",
      "\n",
      "Cleaning text data...\n",
      "\n",
      "Cleaned Data Head:\n",
      "                             job_description_cleaned  \\\n",
      "0  data analyst needed with experience in sql, ex...   \n",
      "1  data scientist needed with experience in stati...   \n",
      "2  software engineer needed with experience in sy...   \n",
      "3  ml engineer needed with experience in python, ...   \n",
      "4  software engineer needed with experience in re...   \n",
      "\n",
      "                                      resume_cleaned  match_score  \n",
      "0  experienced professional skilled in sql, power...            4  \n",
      "1  experienced professional skilled in python, de...            4  \n",
      "2  experienced professional skilled in wait, git,...            5  \n",
      "3  experienced professional skilled in return, de...            4  \n",
      "4  experienced professional skilled in rest apis,...            5  \n",
      "\n",
      "Data cleaning complete. You now have 'job_description_cleaned' and 'resume_cleaned' columns.\n",
      "This DataFrame (df) can now be used for BERT embedding generation.\n",
      "\n",
      "Cleaned data saved to ./data/cleaned_resume_job_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import zipfile\n",
    "import json\n",
    "\n",
    "# --- Configuration ---\n",
    "# You will need to set up your Kaggle API key to download datasets.\n",
    "# 1. Go to Kaggle.com -> Your Profile -> Account -> Create New API Token.\n",
    "# 2. This will download a kaggle.json file.\n",
    "# 3. Place this file in ~/.kaggle/ (Linux/macOS) or C:\\Users\\<Windows-username>\\.kaggle\\ (Windows).\n",
    "#    Alternatively, set KAGGLE_USERNAME and KAGGLE_KEY environment variables.\n",
    "# For this script to run in a controlled environment, we'll simulate the data loading\n",
    "# if Kaggle API is not configured or if we're in a restricted environment.\n",
    "# In your local setup, you would use `kaggle datasets download ...`\n",
    "\n",
    "DATASET_NAME = \"shamimhasan8/resume-vs-job-description-matching-dataset\"\n",
    "DOWNLOAD_PATH = \"./data\"\n",
    "CSV_FILE_NAME = \"resume_job_matching_dataset.csv\"\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def download_kaggle_dataset(dataset_name, path):\n",
    "    \"\"\"\n",
    "    Downloads a Kaggle dataset using the Kaggle API.\n",
    "    This function assumes Kaggle API is configured (kaggle.json or env vars).\n",
    "    \"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    print(f\"Attempting to download {dataset_name} to {path}...\")\n",
    "    try:\n",
    "        # This command requires the 'kaggle' package to be installed: pip install kaggle\n",
    "        # It also requires your Kaggle API key to be set up.\n",
    "        os.system(f\"kaggle datasets download -d {dataset_name} -p {path}\")\n",
    "        print(\"Download command executed. Checking for zip file...\")\n",
    "        # Find the downloaded zip file\n",
    "        zip_files = [f for f in os.listdir(path) if f.endswith('.zip')]\n",
    "        if zip_files:\n",
    "            zip_path = os.path.join(path, zip_files[0])\n",
    "            print(f\"Found zip file: {zip_path}. Unzipping...\")\n",
    "            with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall(path)\n",
    "            print(\"Dataset unzipped successfully.\")\n",
    "            os.remove(zip_path) # Clean up the zip file\n",
    "            return True\n",
    "        else:\n",
    "            print(\"No zip file found after download command. Please ensure Kaggle API is configured correctly.\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading Kaggle dataset: {e}\")\n",
    "        print(\"Please ensure you have the 'kaggle' package installed (`pip install kaggle`)\")\n",
    "        print(\"and your Kaggle API key is configured (see comments in script).\")\n",
    "        return False\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Performs basic text cleaning:\n",
    "    - Removes extra whitespace\n",
    "    - Converts to lowercase\n",
    "    - Removes special characters (keeping alphanumeric and basic punctuation)\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = text.lower() # Convert to lowercase\n",
    "    text = re.sub(r'\\s+', ' ', text).strip() # Remove extra whitespace\n",
    "    # You might want to refine this regex based on what characters are truly\n",
    "    # irrelevant for your NLP task. For now, keep letters, numbers, and some basic punctuation.\n",
    "    text = re.sub(r'[^a-z0-9\\s.,;\\'\"!?]', '', text)\n",
    "    return text\n",
    "\n",
    "# --- Main Script ---\n",
    "\n",
    "def main():\n",
    "    # Check if the CSV file already exists\n",
    "    csv_path = os.path.join(DOWNLOAD_PATH, CSV_FILE_NAME)\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"'{CSV_FILE_NAME}' not found. Attempting to download from Kaggle...\")\n",
    "        success = download_kaggle_dataset(DATASET_NAME, DOWNLOAD_PATH)\n",
    "        if not success:\n",
    "            print(\"Failed to download dataset. Please download it manually and place it in the 'data' folder.\")\n",
    "            print(f\"You can download from: https://www.kaggle.com/datasets/{DATASET_NAME}\")\n",
    "            print(f\"Ensure the CSV file is named '{CSV_FILE_NAME}' inside the '{DOWNLOAD_PATH}' directory.\")\n",
    "            # For demonstration purposes, let's create a dummy file if download fails\n",
    "            print(\"Creating a dummy CSV for demonstration if download fails...\")\n",
    "            dummy_data = {\n",
    "                'job_description': [\n",
    "                    \"We are looking for a highly motivated Software Engineer with strong Python skills and experience in machine learning.\",\n",
    "                    \"Seeking a Data Scientist with expertise in statistical modeling, R, and data visualization. PhD preferred.\",\n",
    "                    \"Junior Developer position, requiring basic understanding of web development (HTML, CSS, JS) and problem-solving skills.\"\n",
    "                ],\n",
    "                'resume': [\n",
    "                    \"Experienced Python developer with a background in deep learning projects and strong coding abilities.\",\n",
    "                    \"Statistician with a Master's degree, proficient in R and data analysis, created interactive dashboards.\",\n",
    "                    \"Recent graduate eager to learn, completed a bootcamp in front-end technologies including HTML and CSS.\"\n",
    "                ],\n",
    "                'match_score': [5, 4, 3]\n",
    "            }\n",
    "            pd.DataFrame(dummy_data).to_csv(csv_path, index=False)\n",
    "            print(\"Dummy CSV created. Proceeding with dummy data.\")\n",
    "    else:\n",
    "        print(f\"'{CSV_FILE_NAME}' found. Loading existing data.\")\n",
    "\n",
    "    try:\n",
    "        # Load the dataset\n",
    "        df = pd.read_csv(csv_path)\n",
    "        print(\"\\nOriginal Data Head:\")\n",
    "        print(df.head())\n",
    "        print(f\"\\nOriginal Data Shape: {df.shape}\")\n",
    "\n",
    "        # Apply text cleaning\n",
    "        print(\"\\nCleaning text data...\")\n",
    "        df['job_description_cleaned'] = df['job_description'].apply(clean_text)\n",
    "        df['resume_cleaned'] = df['resume'].apply(clean_text)\n",
    "\n",
    "        print(\"\\nCleaned Data Head:\")\n",
    "        print(df[['job_description_cleaned', 'resume_cleaned', 'match_score']].head())\n",
    "\n",
    "        print(\"\\nData cleaning complete. You now have 'job_description_cleaned' and 'resume_cleaned' columns.\")\n",
    "        print(\"This DataFrame (df) can now be used for BERT embedding generation.\")\n",
    "\n",
    "        # Save the cleaned data for future use (optional)\n",
    "        df.to_csv(os.path.join(DOWNLOAD_PATH, \"cleaned_resume_job_data.csv\"), index=False)\n",
    "        print(f\"\\nCleaned data saved to {os.path.join(DOWNLOAD_PATH, 'cleaned_resume_job_data.csv')}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{csv_path}' was not found. Please ensure it's in the correct directory.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c4006c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
