{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61926382",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression # A simple, interpretable model\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "692bf9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded for modeling.\n",
      "Input data from: ./data/resume_job_match_with_similarity.csv\n",
      "Good match threshold: 4\n",
      "Loaded data for modeling. Shape: (10000, 6)\n",
      "\n",
      "Sample of data for modeling (first 5 rows):\n",
      "   match_score  bert_similarity_score\n",
      "0            4               0.652394\n",
      "1            4               0.372719\n",
      "2            5               0.447902\n",
      "3            4               0.516451\n",
      "4            5               0.451312\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "# Path to the data with BERT similarity scores\n",
    "INPUT_CSV_PATH = \"./data/resume_job_match_with_similarity.csv\"\n",
    "# Threshold for defining a \"good match\" from the original match_score (1-5)\n",
    "GOOD_MATCH_THRESHOLD = 4\n",
    "\n",
    "print(\"Configuration loaded for modeling.\")\n",
    "print(f\"Input data from: {INPUT_CSV_PATH}\")\n",
    "print(f\"Good match threshold: {GOOD_MATCH_THRESHOLD}\")\n",
    "\n",
    "# Load the dataset\n",
    "if not os.path.exists(INPUT_CSV_PATH):\n",
    "    print(f\"Error: Input data file not found at '{INPUT_CSV_PATH}'.\")\n",
    "    print(\"Please ensure the previous BERT matching script ran successfully and saved the file.\")\n",
    "else:\n",
    "    try:\n",
    "        df = pd.read_csv(INPUT_CSV_PATH)\n",
    "        print(f\"Loaded data for modeling. Shape: {df.shape}\")\n",
    "        print(\"\\nSample of data for modeling (first 5 rows):\")\n",
    "        print(df[['match_score', 'bert_similarity_score']].head())\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data for modeling: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85ffa54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Created 'is_good_match' column. Counts:\n",
      "is_good_match\n",
      "1    5401\n",
      "0    4599\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Data split into training (8000 samples) and testing (2000 samples).\n",
      "Training target distribution:\n",
      "is_good_match\n",
      "1    0.53825\n",
      "0    0.46175\n",
      "Name: proportion, dtype: float64\n",
      "Testing target distribution:\n",
      "is_good_match\n",
      "1    0.5475\n",
      "0    0.4525\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Cell 8 (or new notebook Cell 2): Prepare Data for Classification\n",
    "\n",
    "# Create the target variable: 1 for \"good match\", 0 for \"not a good match\"\n",
    "df['is_good_match'] = (df['match_score'] >= GOOD_MATCH_THRESHOLD).astype(int)\n",
    "\n",
    "print(f\"\\nCreated 'is_good_match' column. Counts:\")\n",
    "print(df['is_good_match'].value_counts())\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "# For now, we'll use only the BERT similarity score as our feature\n",
    "X = df[['bert_similarity_score']]\n",
    "y = df['is_good_match']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# test_size=0.2 means 20% of the data will be used for testing\n",
    "# random_state for reproducibility\n",
    "# For very small datasets, stratify may fail if a class has <2 samples\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"\\nData split into training ({len(X_train)} samples) and testing ({len(X_test)} samples).\")\n",
    "print(f\"Training target distribution:\\n{y_train.value_counts(normalize=True)}\")\n",
    "print(f\"Testing target distribution:\\n{y_test.value_counts(normalize=True)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d12b042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Logistic Regression model...\n",
      "Model training complete.\n",
      "\n",
      "Evaluating model performance:\n",
      "Accuracy: 0.6765\n",
      "Precision: 0.6821\n",
      "Recall: 0.7662\n",
      "F1-Score: 0.7217\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.57      0.61       905\n",
      "           1       0.68      0.77      0.72      1095\n",
      "\n",
      "    accuracy                           0.68      2000\n",
      "   macro avg       0.67      0.67      0.67      2000\n",
      "weighted avg       0.68      0.68      0.67      2000\n",
      "\n",
      "\n",
      "Model trained and evaluated. This model can now be used for basic resume screening/shortlisting.\n",
      "Candidates with a predicted 'is_good_match' of 1 would be shortlisted.\n"
     ]
    }
   ],
   "source": [
    "# Cell 9 (or new notebook Cell 3): Train and Evaluate the Model\n",
    "\n",
    "print(\"\\nTraining Logistic Regression model...\")\n",
    "# Initialize and train the Logistic Regression model\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"\\nEvaluating model performance:\")\n",
    "# Calculate common classification metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nModel trained and evaluated. This model can now be used for basic resume screening/shortlisting.\")\n",
    "print(\"Candidates with a predicted 'is_good_match' of 1 would be shortlisted.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6326c206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data for gender simulation. Shape: (10000, 6)\n",
      "\n",
      "Simulated 'simulated_gender' column. Counts:\n",
      "simulated_gender\n",
      "Male      5013\n",
      "Female    4987\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample of data with simulated gender (first 5 rows):\n",
      "                                              resume  \\\n",
      "0  Experienced professional skilled in SQL, Power...   \n",
      "1  Experienced professional skilled in Python, De...   \n",
      "2  Experienced professional skilled in wait, Git,...   \n",
      "3  Experienced professional skilled in return, De...   \n",
      "4  Experienced professional skilled in REST APIs,...   \n",
      "\n",
      "                                     job_description  bert_similarity_score  \\\n",
      "0  Data Analyst needed with experience in SQL, Ex...               0.652394   \n",
      "1  Data Scientist needed with experience in Stati...               0.372719   \n",
      "2  Software Engineer needed with experience in Sy...               0.447902   \n",
      "3  ML Engineer needed with experience in Python, ...               0.516451   \n",
      "4  Software Engineer needed with experience in RE...               0.451312   \n",
      "\n",
      "   match_score simulated_gender  \n",
      "0            4             Male  \n",
      "1            4           Female  \n",
      "2            5             Male  \n",
      "3            4             Male  \n",
      "4            5             Male  \n",
      "\n",
      "DataFrame with simulated gender saved to: ./data/resume_job_match_with_gender.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- Configuration ---\n",
    "# Path to the data with BERT similarity scores (output from previous step)\n",
    "INPUT_CSV_PATH_WITH_SIMILARITY = \"./data/resume_job_match_with_similarity.csv\"\n",
    "OUTPUT_CSV_PATH_WITH_GENDER = \"./data/resume_job_match_with_gender.csv\"\n",
    "\n",
    "# Load the dataset with similarity scores\n",
    "if not os.path.exists(INPUT_CSV_PATH_WITH_SIMILARITY):\n",
    "    print(f\"Error: Input data file not found at '{INPUT_CSV_PATH_WITH_SIMILARITY}'.\")\n",
    "    print(\"Please ensure the previous BERT matching script ran successfully and saved the file.\")\n",
    "else:\n",
    "    try:\n",
    "        df_with_sim = pd.read_csv(INPUT_CSV_PATH_WITH_SIMILARITY)\n",
    "        print(f\"Loaded data for gender simulation. Shape: {df_with_sim.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data for gender simulation: {e}\")\n",
    "\n",
    "# Simulate a 'gender' column\n",
    "# For demonstration, we'll assign 'Male' or 'Female' randomly.\n",
    "# In a real research scenario, you might want to simulate a specific distribution\n",
    "# or even introduce a subtle bias in the synthetic data generation itself\n",
    "# to then demonstrate mitigation.\n",
    "np.random.seed(42) # for reproducibility\n",
    "df_with_sim['simulated_gender'] = np.random.choice(['Male', 'Female'], size=len(df_with_sim))\n",
    "\n",
    "print(\"\\nSimulated 'simulated_gender' column. Counts:\")\n",
    "print(df_with_sim['simulated_gender'].value_counts())\n",
    "\n",
    "print(\"\\nSample of data with simulated gender (first 5 rows):\")\n",
    "print(df_with_sim[['resume', 'job_description', 'bert_similarity_score', 'match_score', 'simulated_gender']].head())\n",
    "\n",
    "# Save the DataFrame with the simulated gender\n",
    "try:\n",
    "    df_with_sim.to_csv(OUTPUT_CSV_PATH_WITH_GENDER, index=False)\n",
    "    print(f\"\\nDataFrame with simulated gender saved to: {OUTPUT_CSV_PATH_WITH_GENDER}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving data with simulated gender: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03a2dfa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded for bias measurement.\n",
      "Input data from: ./data/resume_job_match_with_gender.csv\n",
      "Loaded data for bias measurement. Shape: (10000, 7)\n",
      "\n",
      "Sample of data with simulated gender:\n",
      "   match_score  bert_similarity_score simulated_gender\n",
      "0            4               0.652394             Male\n",
      "1            4               0.372719           Female\n",
      "2            5               0.447902             Male\n",
      "3            4               0.516451             Male\n",
      "4            5               0.451312             Male\n",
      "\n",
      "Data split into training (8000 samples) and testing (2000 samples).\n",
      "Training sensitive attribute distribution:\n",
      "simulated_gender\n",
      "Male      0.500875\n",
      "Female    0.499125\n",
      "Name: proportion, dtype: float64\n",
      "Testing sensitive attribute distribution:\n",
      "simulated_gender\n",
      "Male      0.503\n",
      "Female    0.497\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Cell 11 (or new notebook Cell 1): Setup for Bias Measurement\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from fairlearn.metrics import MetricFrame, demographic_parity_ratio, equalized_odds_ratio\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# --- Configuration ---\n",
    "# Path to the data with BERT similarity scores and simulated gender\n",
    "INPUT_CSV_PATH_WITH_GENDER = \"./data/resume_job_match_with_gender.csv\"\n",
    "GOOD_MATCH_THRESHOLD = 4 # Same threshold as before for 'is_good_match'\n",
    "\n",
    "print(\"Configuration loaded for bias measurement.\")\n",
    "print(f\"Input data from: {INPUT_CSV_PATH_WITH_GENDER}\")\n",
    "\n",
    "# Load the dataset with simulated gender\n",
    "if not os.path.exists(INPUT_CSV_PATH_WITH_GENDER):\n",
    "    print(f\"Error: Input data file not found at '{INPUT_CSV_PATH_WITH_GENDER}'.\")\n",
    "    print(\"Please ensure the previous gender simulation script ran successfully and saved the file.\")\n",
    "else:\n",
    "    try:\n",
    "        df = pd.read_csv(INPUT_CSV_PATH_WITH_GENDER)\n",
    "        print(f\"Loaded data for bias measurement. Shape: {df.shape}\")\n",
    "        print(\"\\nSample of data with simulated gender:\")\n",
    "        print(df[['match_score', 'bert_similarity_score', 'simulated_gender']].head())\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data for bias measurement: {e}\")\n",
    "\n",
    "# Create the target variable: 1 for \"good match\", 0 for \"not a good match\"\n",
    "df['is_good_match'] = (df['match_score'] >= GOOD_MATCH_THRESHOLD).astype(int)\n",
    "\n",
    "# Define features (X), target (y), and sensitive attribute (A)\n",
    "X = df[['bert_similarity_score']]\n",
    "y = df['is_good_match']\n",
    "A = df['simulated_gender'] # Our sensitive attribute\n",
    "\n",
    "# Split the data into training and testing sets, ensuring sensitive attribute distribution is maintained\n",
    "X_train, X_test, y_train, y_test, A_train, A_test = train_test_split(\n",
    "    X, y, A, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nData split into training ({len(X_train)} samples) and testing ({len(X_test)} samples).\")\n",
    "print(f\"Training sensitive attribute distribution:\\n{A_train.value_counts(normalize=True)}\")\n",
    "print(f\"Testing sensitive attribute distribution:\\n{A_test.value_counts(normalize=True)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "990ecc0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training baseline Logistic Regression model for bias measurement...\n",
      "Baseline model training complete.\n",
      "\n",
      "--- Baseline Model Performance (Overall) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.57      0.61       905\n",
      "           1       0.68      0.77      0.72      1095\n",
      "\n",
      "    accuracy                           0.68      2000\n",
      "   macro avg       0.67      0.67      0.67      2000\n",
      "weighted avg       0.68      0.68      0.67      2000\n",
      "\n",
      "\n",
      "--- Fairness Metrics (Baseline Model) ---\n",
      "Demographic Parity Ratio: 0.9607 (closer to 1 is fairer)\n",
      "Equalized Odds Ratio (True Positive Rate): 0.8289 (closer to 1 is fairer)\n",
      "\n",
      "Accuracy per simulated gender group:\n",
      "simulated_gender\n",
      "Female    0.702213\n",
      "Male      0.651093\n",
      "Name: accuracy_score, dtype: float64\n",
      "\n",
      "Recall (True Positive Rate) per simulated gender group:\n",
      "simulated_gender\n",
      "Female    0.783178\n",
      "Male      0.750000\n",
      "Name: recall_score, dtype: float64\n",
      "\n",
      "Bias measurement complete for the baseline model.\n",
      "The ratios indicate how close the performance is between the most and least privileged groups.\n",
      "A ratio of 1 means perfect fairness for that metric.\n"
     ]
    }
   ],
   "source": [
    "# Cell 12 (or new notebook Cell 2): Train Baseline Model and Measure Bias\n",
    "\n",
    "print(\"\\nTraining baseline Logistic Regression model for bias measurement...\")\n",
    "model_baseline = LogisticRegression(random_state=42)\n",
    "model_baseline.fit(X_train, y_train)\n",
    "print(\"Baseline model training complete.\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_baseline = model_baseline.predict(X_test)\n",
    "\n",
    "print(\"\\n--- Baseline Model Performance (Overall) ---\")\n",
    "print(classification_report(y_test, y_pred_baseline))\n",
    "\n",
    "# --- Measure Fairness Metrics ---\n",
    "print(\"\\n--- Fairness Metrics (Baseline Model) ---\")\n",
    "\n",
    "# Demographic Parity: Selection rate across groups\n",
    "# A higher ratio (closer to 1) indicates better demographic parity\n",
    "dp_ratio = demographic_parity_ratio(y_true=y_test, y_pred=y_pred_baseline, sensitive_features=A_test)\n",
    "print(f\"Demographic Parity Ratio: {dp_ratio:.4f} (closer to 1 is fairer)\")\n",
    "\n",
    "# Equalized Odds: True Positive Rate (Recall) across groups\n",
    "# A higher ratio (closer to 1) indicates better equalized odds\n",
    "eo_ratio = equalized_odds_ratio(y_true=y_test, y_pred=y_pred_baseline, sensitive_features=A_test)\n",
    "print(f\"Equalized Odds Ratio (True Positive Rate): {eo_ratio:.4f} (closer to 1 is fairer)\")\n",
    "\n",
    "# Detailed metrics per group using MetricFrame\n",
    "grouped_on_gender = MetricFrame(metrics=accuracy_score,\n",
    "                                y_true=y_test,\n",
    "                                y_pred=y_pred_baseline,\n",
    "                                sensitive_features=A_test)\n",
    "print(\"\\nAccuracy per simulated gender group:\")\n",
    "print(grouped_on_gender.by_group)\n",
    "\n",
    "grouped_on_gender_recall = MetricFrame(metrics=recall_score,\n",
    "                                       y_true=y_test,\n",
    "                                       y_pred=y_pred_baseline,\n",
    "                                       sensitive_features=A_test)\n",
    "print(\"\\nRecall (True Positive Rate) per simulated gender group:\")\n",
    "print(grouped_on_gender_recall.by_group)\n",
    "\n",
    "print(\"\\nBias measurement complete for the baseline model.\")\n",
    "print(\"The ratios indicate how close the performance is between the most and least privileged groups.\")\n",
    "print(\"A ratio of 1 means perfect fairness for that metric.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59011d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded for bias measurement.\n",
      "Input data from: ./data/resume_job_match_with_gender.csv\n",
      "Loaded data for bias measurement. Shape: (10000, 7)\n",
      "\n",
      "Sample of data with simulated gender:\n",
      "   match_score  bert_similarity_score simulated_gender\n",
      "0            4               0.652394             Male\n",
      "1            4               0.372719           Female\n",
      "2            5               0.447902             Male\n",
      "3            4               0.516451             Male\n",
      "4            5               0.451312             Male\n",
      "\n",
      "--- Using the FULL small dataset for fairness evaluation (DEMO ONLY) ---\n",
      "   For your actual dissertation, please use a proper train/test split on the full dataset.\n",
      "Evaluation dataset shape: (10000, 1)\n",
      "Evaluation sensitive attribute distribution:\n",
      "simulated_gender\n",
      "Male      0.5013\n",
      "Female    0.4987\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Model training data split: training (8000 samples), testing (2000 samples).\n",
      "\n",
      "Training baseline Logistic Regression model...\n",
      "Baseline model training complete.\n",
      "Predictions made on evaluation set.\n",
      "\n",
      "--- Baseline Model Performance (Overall on Evaluation Set) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.57      0.62      4599\n",
      "           1       0.68      0.76      0.71      5401\n",
      "\n",
      "    accuracy                           0.67     10000\n",
      "   macro avg       0.67      0.67      0.67     10000\n",
      "weighted avg       0.67      0.67      0.67     10000\n",
      "\n",
      "\n",
      "--- Fairness Metrics (Baseline Model on Evaluation Set) ---\n",
      "Demographic Parity Ratio: 0.9917 (closer to 1 is fairer)\n",
      "Equalized Odds Ratio (True Positive Rate): 0.9735 (closer to 1 is fairer)\n",
      "\n",
      "Accuracy per simulated gender group:\n",
      "sensitive_feature_0\n",
      "Female    0.675556\n",
      "Male      0.670856\n",
      "Name: accuracy_score, dtype: float64\n",
      "\n",
      "Recall (True Positive Rate) per simulated gender group:\n",
      "sensitive_feature_0\n",
      "Female    0.756098\n",
      "Male      0.758813\n",
      "Name: metric, dtype: float64\n",
      "\n",
      "Bias measurement complete for the baseline model (on evaluation set).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nishmaanair/Desktop/ai_recruitment_tool/venv/lib/python3.11/site-packages/fairlearn/metrics/_annotated_metric_function.py:65: UserWarning: Supplied 'func' had no __name__ attribute\n",
      "  warnings.warn(\"Supplied 'func' had no __name__ attribute\")\n"
     ]
    }
   ],
   "source": [
    "# Cell 11 (or new notebook Cell 1): Setup for Bias Measurement (Revised)\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split # Still useful for initial model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from fairlearn.metrics import MetricFrame, demographic_parity_ratio, equalized_odds_ratio\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# --- Configuration ---\n",
    "INPUT_CSV_PATH_WITH_GENDER = \"./data/resume_job_match_with_gender.csv\"\n",
    "GOOD_MATCH_THRESHOLD = 4\n",
    "\n",
    "print(\"Configuration loaded for bias measurement.\")\n",
    "print(f\"Input data from: {INPUT_CSV_PATH_WITH_GENDER}\")\n",
    "\n",
    "# Load the dataset with simulated gender\n",
    "if not os.path.exists(INPUT_CSV_PATH_WITH_GENDER):\n",
    "    print(f\"Error: Input data file not found at '{INPUT_CSV_PATH_WITH_GENDER}'.\")\n",
    "    print(\"Please ensure the previous gender simulation script ran successfully and saved the file.\")\n",
    "    exit() # Exit if data not found\n",
    "try:\n",
    "    df = pd.read_csv(INPUT_CSV_PATH_WITH_GENDER)\n",
    "    print(f\"Loaded data for bias measurement. Shape: {df.shape}\")\n",
    "    print(\"\\nSample of data with simulated gender:\")\n",
    "    print(df[['match_score', 'bert_similarity_score', 'simulated_gender']].head())\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data for bias measurement: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Create the target variable: 1 for \"good match\", 0 for \"not a good match\"\n",
    "df['is_good_match'] = (df['match_score'] >= GOOD_MATCH_THRESHOLD).astype(int)\n",
    "\n",
    "# Define features (X), target (y), and sensitive attribute (A)\n",
    "X = df[['bert_similarity_score']]\n",
    "y = df['is_good_match']\n",
    "A = df['simulated_gender'] # Our sensitive attribute\n",
    "\n",
    "# --- IMPORTANT FOR SMALL DATASET DEMO ---\n",
    "# For a real dissertation, use train_test_split here for X_train, X_test, y_train, y_test, A_train, A_test.\n",
    "# For this tiny demo, we'll use the full dataset for fairness calculation to avoid empty groups.\n",
    "# So, X_eval, y_eval, A_eval will represent the data used for *evaluation* of fairness.\n",
    "# If you were to split, the test set might contain only one group, causing errors.\n",
    "X_eval = X # Use full X for fairness evaluation\n",
    "y_eval = y # Use full y for fairness evaluation\n",
    "A_eval = A # Use full A for fairness evaluation\n",
    "\n",
    "print(\"\\n--- Using the FULL small dataset for fairness evaluation (DEMO ONLY) ---\")\n",
    "print(\"   For your actual dissertation, please use a proper train/test split on the full dataset.\")\n",
    "print(f\"Evaluation dataset shape: {X_eval.shape}\")\n",
    "print(f\"Evaluation sensitive attribute distribution:\\n{A_eval.value_counts(normalize=True)}\")\n",
    "\n",
    "# Split the data into training and testing sets for the *model training*\n",
    "# This is separate from the fairness evaluation set, to ensure model is trained on distinct data\n",
    "# With 3 samples, this split will be very tiny.\n",
    "X_train, X_test, y_train, y_test, A_train, A_test = train_test_split(\n",
    "    X, y, A, test_size=0.2, random_state=42\n",
    ")\n",
    "print(f\"\\nModel training data split: training ({len(X_train)} samples), testing ({len(X_test)} samples).\")\n",
    "\n",
    "\n",
    "# Cell 12 (or new notebook Cell 2): Train Baseline Model and Measure Bias (Revised)\n",
    "\n",
    "print(\"\\nTraining baseline Logistic Regression model...\")\n",
    "model_baseline = LogisticRegression(random_state=42)\n",
    "model_baseline.fit(X_train, y_train) # Train on X_train, y_train\n",
    "print(\"Baseline model training complete.\")\n",
    "\n",
    "# Make predictions on the *evaluation* set for fairness metrics\n",
    "y_pred_baseline = model_baseline.predict(X_eval) # Predict on X_eval\n",
    "print(\"Predictions made on evaluation set.\")\n",
    "\n",
    "print(\"\\n--- Baseline Model Performance (Overall on Evaluation Set) ---\")\n",
    "# Classification report on y_eval and y_pred_baseline\n",
    "# Note: For 3 data points, this report won't be very informative.\n",
    "print(classification_report(y_eval, y_pred_baseline, zero_division=0)) # zero_division=0 to handle cases where a class has no predictions\n",
    "\n",
    "# --- Measure Fairness Metrics ---\n",
    "print(\"\\n--- Fairness Metrics (Baseline Model on Evaluation Set) ---\")\n",
    "\n",
    "# Demographic Parity: Selection rate across groups\n",
    "dp_ratio = demographic_parity_ratio(y_true=y_eval, y_pred=y_pred_baseline, sensitive_features=A_eval.tolist())\n",
    "print(f\"Demographic Parity Ratio: {dp_ratio:.4f} (closer to 1 is fairer)\")\n",
    "\n",
    "# Equalized Odds: True Positive Rate (Recall) across groups\n",
    "eo_ratio = equalized_odds_ratio(y_true=y_eval, y_pred=y_pred_baseline, sensitive_features=A_eval.tolist())\n",
    "print(f\"Equalized Odds Ratio (True Positive Rate): {eo_ratio:.4f} (closer to 1 is fairer)\")\n",
    "\n",
    "# Detailed metrics per group using MetricFrame\n",
    "grouped_on_gender = MetricFrame(metrics=accuracy_score,\n",
    "                                y_true=y_eval,\n",
    "                                y_pred=y_pred_baseline,\n",
    "                                sensitive_features=A_eval.tolist())\n",
    "print(\"\\nAccuracy per simulated gender group:\")\n",
    "print(grouped_on_gender.by_group)\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "grouped_on_gender_recall = MetricFrame(metrics=partial(recall_score, zero_division=0),\n",
    "                                       y_true=y_eval,\n",
    "                                       y_pred=y_pred_baseline,\n",
    "                                       sensitive_features=A_eval.tolist())\n",
    "print(\"\\nRecall (True Positive Rate) per simulated gender group:\")\n",
    "print(grouped_on_gender_recall.by_group)\n",
    "\n",
    "print(\"\\nBias measurement complete for the baseline model (on evaluation set).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f393860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Applying Bias Mitigation using ThresholdOptimizer ---\n",
      "ThresholdOptimizer fitted.\n",
      "Mitigated predictions generated.\n",
      "\n",
      "--- Mitigated Model Performance (Overall on Evaluation Set) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.59      0.62      4599\n",
      "           1       0.68      0.75      0.71      5401\n",
      "\n",
      "    accuracy                           0.68     10000\n",
      "   macro avg       0.67      0.67      0.67     10000\n",
      "weighted avg       0.67      0.68      0.67     10000\n",
      "\n",
      "\n",
      "--- Fairness Metrics (Mitigated Model on Evaluation Set) ---\n",
      "Demographic Parity Ratio (Mitigated): 0.9935 (closer to 1 is fairer)\n",
      "Equalized Odds Ratio (True Positive Rate) (Mitigated): 0.9947 (closer to 1 is fairer)\n",
      "\n",
      "Accuracy per simulated gender group (Mitigated):\n",
      "sensitive_feature_0\n",
      "Female    0.676960\n",
      "Male      0.674047\n",
      "Name: accuracy_score, dtype: float64\n",
      "\n",
      "Recall (True Positive Rate) per simulated gender group (Mitigated):\n",
      "sensitive_feature_0\n",
      "Female    0.753511\n",
      "Male      0.749536\n",
      "Name: metric, dtype: float64\n",
      "\n",
      "Bias mitigation complete. Compare the 'Mitigated' ratios and group metrics to the 'Baseline' ones.\n",
      "You should observe an improvement in the fairness metric you chose for mitigation (e.g., Equalized Odds).\n",
      "Note: Mitigation often involves a trade-off with overall accuracy.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nishmaanair/Desktop/ai_recruitment_tool/venv/lib/python3.11/site-packages/fairlearn/metrics/_annotated_metric_function.py:65: UserWarning: Supplied 'func' had no __name__ attribute\n",
      "  warnings.warn(\"Supplied 'func' had no __name__ attribute\")\n"
     ]
    }
   ],
   "source": [
    "# Cell 13 (or new notebook Cell 3): Apply Bias Mitigation (Post-processing) (Revised)\n",
    "\n",
    "from fairlearn.postprocessing import ThresholdOptimizer\n",
    "\n",
    "print(\"\\n--- Applying Bias Mitigation using ThresholdOptimizer ---\")\n",
    "\n",
    "# We need the predicted probabilities from the baseline model to use ThresholdOptimizer\n",
    "# These probabilities should be from the model predicting on the *evaluation* set (X_eval)\n",
    "y_pred_proba_baseline = model_baseline.predict_proba(X_eval)[:, 1]\n",
    "\n",
    "# Initialize ThresholdOptimizer\n",
    "mitigator = ThresholdOptimizer(\n",
    "    estimator=model_baseline,\n",
    "    constraints=\"equalized_odds\", # Using string name for the constraint\n",
    "    objective='accuracy_score',\n",
    "    prefit=True # Our model_baseline is already fitted\n",
    ")\n",
    "\n",
    "# Check for degenerate groups (groups with only one class in y_eval)\n",
    "degenerate_groups = []\n",
    "for group in A_eval.unique():\n",
    "    labels = y_eval[A_eval == group]\n",
    "    if len(labels.unique()) < 2:\n",
    "        degenerate_groups.append(group)\n",
    "\n",
    "if degenerate_groups:\n",
    "    print(f\"Cannot apply ThresholdOptimizer: degenerate label(s) for group(s): {degenerate_groups}\")\n",
    "    print(\"Each group in the sensitive attribute must have both positive and negative labels in y_eval.\")\n",
    "    print(\"Please use a larger dataset or adjust your data split.\")\n",
    "    y_pred_mitigated = None\n",
    "else:\n",
    "    # Fit the mitigator on the *evaluation* data (X_eval, y_eval, A_eval)\n",
    "    # This step determines the optimal thresholds for each group\n",
    "    # --- Using X_eval, y_eval, A_eval.tolist() ---\n",
    "    mitigator.fit(X_eval, y_eval, sensitive_features=A_eval.tolist())\n",
    "    print(\"ThresholdOptimizer fitted.\")\n",
    "    # Make mitigated predictions using the mitigator on the *evaluation* data\n",
    "    # --- Using X_eval, A_eval.tolist() ---\n",
    "    y_pred_mitigated = mitigator.predict(X_eval, sensitive_features=A_eval.tolist())\n",
    "    print(\"Mitigated predictions generated.\")\n",
    "\n",
    "    print(\"\\n--- Mitigated Model Performance (Overall on Evaluation Set) ---\")\n",
    "    print(classification_report(y_eval, y_pred_mitigated, zero_division=0))\n",
    "\n",
    "    # --- Measure Fairness Metrics for Mitigated Model ---\n",
    "    print(\"\\n--- Fairness Metrics (Mitigated Model on Evaluation Set) ---\")\n",
    "\n",
    "    # --- Using A_eval.tolist() for all Fairlearn metric calls ---\n",
    "    dp_ratio_mitigated = demographic_parity_ratio(y_true=y_eval, y_pred=y_pred_mitigated, sensitive_features=A_eval.tolist())\n",
    "    print(f\"Demographic Parity Ratio (Mitigated): {dp_ratio_mitigated:.4f} (closer to 1 is fairer)\")\n",
    "\n",
    "    eo_ratio_mitigated = equalized_odds_ratio(y_true=y_eval, y_pred=y_pred_mitigated, sensitive_features=A_eval.tolist())\n",
    "    print(f\"Equalized Odds Ratio (True Positive Rate) (Mitigated): {eo_ratio_mitigated:.4f} (closer to 1 is fairer)\")\n",
    "\n",
    "    # Detailed metrics per group for mitigated model\n",
    "    grouped_on_gender_mitigated = MetricFrame(metrics=accuracy_score,\n",
    "                                              y_true=y_eval,\n",
    "                                              y_pred=y_pred_mitigated,\n",
    "                                              sensitive_features=A_eval.tolist())\n",
    "    print(\"\\nAccuracy per simulated gender group (Mitigated):\")\n",
    "    print(grouped_on_gender_mitigated.by_group)\n",
    "\n",
    "    from functools import partial\n",
    "    grouped_on_gender_recall_mitigated = MetricFrame(metrics=partial(recall_score, zero_division=0),\n",
    "                                                     y_true=y_eval,\n",
    "                                                     y_pred=y_pred_mitigated,\n",
    "                                                     sensitive_features=A_eval.tolist())\n",
    "    print(\"\\nRecall (True Positive Rate) per simulated gender group (Mitigated):\")\n",
    "    print(grouped_on_gender_recall_mitigated.by_group)\n",
    "\n",
    "    print(\"\\nBias mitigation complete. Compare the 'Mitigated' ratios and group metrics to the 'Baseline' ones.\")\n",
    "    print(\"You should observe an improvement in the fairness metric you chose for mitigation (e.g., Equalized Odds).\")\n",
    "    print(\"Note: Mitigation often involves a trade-off with overall accuracy.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
